{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7abc88f-53f8-4258-b343-0866d68a8482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6896ffc-24ac-4285-b372-69983e2360d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEASON_ID</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "      <th>PLAYER_AGE</th>\n",
       "      <th>GP</th>\n",
       "      <th>GS</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG_PCT</th>\n",
       "      <th>FG3M</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA_PER_GAME</th>\n",
       "      <th>OREB_PER_GAME</th>\n",
       "      <th>DREB_PER_GAME</th>\n",
       "      <th>REB_PER_GAME</th>\n",
       "      <th>AST_PER_GAME</th>\n",
       "      <th>STL_PER_GAME</th>\n",
       "      <th>BLK_PER_GAME</th>\n",
       "      <th>TOV_PER_GAME</th>\n",
       "      <th>PF_PER_GAME</th>\n",
       "      <th>PTS_PER_GAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985-86</td>\n",
       "      <td>LAL</td>\n",
       "      <td>22.0</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>209</td>\n",
       "      <td>388</td>\n",
       "      <td>0.539</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.70</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2.79</td>\n",
       "      <td>6.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986-87</td>\n",
       "      <td>LAL</td>\n",
       "      <td>23.0</td>\n",
       "      <td>79</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>316</td>\n",
       "      <td>587</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.57</td>\n",
       "      <td>2.66</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.78</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.16</td>\n",
       "      <td>10.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987-88</td>\n",
       "      <td>LAL</td>\n",
       "      <td>24.0</td>\n",
       "      <td>82</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2636.0</td>\n",
       "      <td>322</td>\n",
       "      <td>640</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.62</td>\n",
       "      <td>2.99</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.66</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.46</td>\n",
       "      <td>2.49</td>\n",
       "      <td>11.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1988-89</td>\n",
       "      <td>LAL</td>\n",
       "      <td>25.0</td>\n",
       "      <td>82</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2510.0</td>\n",
       "      <td>401</td>\n",
       "      <td>758</td>\n",
       "      <td>0.529</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.38</td>\n",
       "      <td>3.15</td>\n",
       "      <td>5.87</td>\n",
       "      <td>9.01</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.10</td>\n",
       "      <td>13.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1989-90</td>\n",
       "      <td>LAL</td>\n",
       "      <td>26.0</td>\n",
       "      <td>82</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2709.0</td>\n",
       "      <td>385</td>\n",
       "      <td>806</td>\n",
       "      <td>0.478</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.51</td>\n",
       "      <td>3.20</td>\n",
       "      <td>5.49</td>\n",
       "      <td>8.68</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.41</td>\n",
       "      <td>2.52</td>\n",
       "      <td>12.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  SEASON_ID TEAM_ABBREVIATION  PLAYER_AGE  GP    GS     MIN  FGM  FGA  FG_PCT  \\\n",
       "0   1985-86               LAL        22.0  82   1.0  1542.0  209  388   0.539   \n",
       "1   1986-87               LAL        23.0  79  72.0  2240.0  316  587   0.538   \n",
       "2   1987-88               LAL        24.0  82  64.0  2636.0  322  640   0.503   \n",
       "3   1988-89               LAL        25.0  82  82.0  2510.0  401  758   0.529   \n",
       "4   1989-90               LAL        26.0  82  82.0  2709.0  385  806   0.478   \n",
       "\n",
       "   FG3M  ...  FTA_PER_GAME  OREB_PER_GAME  DREB_PER_GAME  REB_PER_GAME  \\\n",
       "0   1.0  ...          2.04           1.95           2.70          4.65   \n",
       "1   0.0  ...          3.57           2.66           5.13          7.78   \n",
       "2   0.0  ...          4.62           2.99           5.67          8.66   \n",
       "3   4.0  ...          4.38           3.15           5.87          9.01   \n",
       "4  13.0  ...          4.51           3.20           5.49          8.68   \n",
       "\n",
       "   AST_PER_GAME  STL_PER_GAME  BLK_PER_GAME  TOV_PER_GAME  PF_PER_GAME  \\\n",
       "0          0.66          0.60          0.60          1.21         2.79   \n",
       "1          1.06          0.89          1.01          1.29         2.16   \n",
       "2          1.13          1.06          0.55          1.46         2.49   \n",
       "3          1.26          1.15          0.67          1.45         2.10   \n",
       "4          1.10          0.80          0.61          1.41         2.52   \n",
       "\n",
       "   PTS_PER_GAME  \n",
       "0          6.35  \n",
       "1         10.78  \n",
       "2         11.43  \n",
       "3         13.27  \n",
       "4         12.94  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full = pd.read_csv(\"nba_player_stats_20250304.csv\")\n",
    "\n",
    "data_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c1d7f15-f021-462f-92a0-06de900a9b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs found in the data\n"
     ]
    }
   ],
   "source": [
    "def check_for_nans(data):\n",
    "    \"\"\"\n",
    "    Check for NaNs in the dataset.\n",
    "    \"\"\"\n",
    "    if data.isna().any().any():\n",
    "        print(\"NaNs found in the data\")\n",
    "    else:\n",
    "        print(\"No NaNs found in the data\")\n",
    "\n",
    "check_for_nans(data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47270450-166b-41a7-aa7d-6fd31b9aba52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaNs: ['GS', 'FG_PCT', 'FG3_PCT', 'FT_PCT']\n"
     ]
    }
   ],
   "source": [
    "def print_rows_with_nans(df):\n",
    "    \"\"\"\n",
    "    Prints out all rows in the DataFrame that contain NaNs along with the unique columns.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to check for NaNs.\n",
    "    \"\"\"\n",
    "    rows_with_nans = df[df.isna().any(axis=1)]\n",
    "    nan_columns = rows_with_nans.columns[rows_with_nans.isna().any()].tolist()\n",
    "    print(f\"Columns with NaNs: {nan_columns}\")\n",
    "\n",
    "print_rows_with_nans(data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0216bff-0be0-4d36-980a-6eb8a0514e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for players traded mid-season, the data has multiple rows containing information for each team they played for. \n",
    "# this breaks the year-by-year sequential structure i want.\n",
    "data_full[\"is_traded\"] = data_full.duplicated(subset=[\"SEASON_ID\", \"PLAYER_NAME\"], keep=False).astype(int) \n",
    "# creating a new column to represent seasons where the player was traded\n",
    "data_full = data_full[(data_full[\"TEAM_ABBREVIATION\"] == \"TOT\") | (data_full[\"is_traded\"] == 0)] # dropping all non \"TOT\" rows for traded players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d348d0-fb94-4159-818f-3bbcb5e758f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = data_full.drop(columns=['GS', 'MIN', 'FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A',\n",
    "       'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL',\n",
    "       'BLK', 'TOV', 'PF', 'PTS']) # these are season totals, i need per game values\n",
    "\n",
    "# Since FG%, GS, FG3%, FT% have nan values I will drop them. They either have redundant data or meaningless data in the case of GS (IMO).\n",
    "# I will add a masking layer so that they don't interfere with the model.\n",
    "# A cleaner solution would be to drop the columns or remove old data but I'll do it this way since there's already so little data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55d369d7-57ce-48e3-819b-7dc2a0524a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = data_full.drop(columns=[\"TEAM_ABBREVIATION\", \"SEASON_ID\"]) # dropping the unnecessary columns except season_start_year and player_name\n",
    "# we'll need them for sorting and grouping later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bccec54-9ace-40e2-8ef3-0fe5e3004349",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = data_full.fillna(-999.0) # just in case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f72ad11-8d62-4232-9616-63d969397f2a",
   "metadata": {},
   "source": [
    "We need to normalize the data but we cant do it normally since there are masked values of -999.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93342d10-eead-4b92-ab6a-ba69992f7e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_full[data_full[\"SEASON_START_YEAR\"] != 2025] # since the 2024-2025 season isnt complete, it shouldnt be used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4173fbc0-13b9-4262-86f3-5501dda9fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normalization_params(df, mask_value=-999.0):\n",
    "    \"\"\"\n",
    "    Compute per-column means and stds ignoring the masked value.\n",
    "    \"\"\"\n",
    "    \n",
    "    columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        \n",
    "    means = {}\n",
    "    stds = {}\n",
    "    for col in columns:\n",
    "        # need to filter out the masked values before computing the statistics\n",
    "        valid_data = df.loc[df[col] != mask_value, col]\n",
    "        means[col] = valid_data.mean()\n",
    "        stds[col] = valid_data.std()\n",
    "    return means, stds\n",
    "\n",
    "def normalize_data(df, means, stds, mask_value=-999.0):\n",
    "    \"\"\"\n",
    "    Normalize data column-wise using provided means and stds while leaving masked values unchanged.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_normalized = df.copy()\n",
    "    columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        \n",
    "    for col in columns:\n",
    "        df_normalized[col] = df_normalized[col].astype(\"float64\")\n",
    "        valid_mask = df_normalized[col] != mask_value # normalize only valid entries\n",
    "        df_normalized.loc[valid_mask, col] = (df_normalized.loc[valid_mask, col] - means[col]) / stds[col]\n",
    "    return df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd570566-18c7-4a31-b429-58c61a674d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stds = compute_normalization_params(data_full)\n",
    "\n",
    "data_full_normalized = normalize_data(data_full, means, stds, mask_value=-999.0)\n",
    "data_normalized = normalize_data(data, means, stds, mask_value=-999.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75b24111-65da-4f65-9936-3be59b2a4263",
   "metadata": {},
   "outputs": [],
   "source": [
    "players = data[\"PLAYER_NAME\"].unique()\n",
    "train_players, val_players = train_test_split(players, test_size=0.1, random_state=42) \n",
    "# i split before creating the sequences. if i split afterwards, i will not be able to validate on out of sample data.\n",
    "\n",
    "train_data = data_normalized[data_normalized[\"PLAYER_NAME\"].isin(train_players)]\n",
    "val_data = data_normalized[data_normalized[\"PLAYER_NAME\"].isin(val_players)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4d2b9a3-08cb-4392-adaf-31ee89c57942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PLAYER_AGE', 'GP', 'SEASON_START_YEAR', 'PLAYER_NAME', 'MIN_PER_GAME',\n",
       "       'FGM_PER_GAME', 'FGA_PER_GAME', 'FG3M_PER_GAME', 'FG3A_PER_GAME',\n",
       "       'FTM_PER_GAME', 'FTA_PER_GAME', 'OREB_PER_GAME', 'DREB_PER_GAME',\n",
       "       'REB_PER_GAME', 'AST_PER_GAME', 'STL_PER_GAME', 'BLK_PER_GAME',\n",
       "       'TOV_PER_GAME', 'PF_PER_GAME', 'PTS_PER_GAME', 'is_traded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42b17b8e-01f9-4918-a4b7-a0a9676c92b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data):\n",
    "    \"\"\"\n",
    "    Create sequences for the entire career of a player.\n",
    "    Each sequence grows in length and the label is the stats we're trying to predict for the following year.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    player_info = []\n",
    "    player_groups = data.groupby(\"PLAYER_NAME\")\n",
    "    \n",
    "    for player_name, group in player_groups:\n",
    "        group = group.sort_values(by=\"SEASON_START_YEAR\").reset_index(drop=True)\n",
    "        \n",
    "        for i in range(1, len(group)):\n",
    "            seq = group.iloc[:i].drop(columns=[\"PLAYER_NAME\", \"SEASON_START_YEAR\"]).values\n",
    "            label = group.iloc[[i]].drop(columns=[\"PLAYER_AGE\", \"PLAYER_NAME\", \"SEASON_START_YEAR\", \"is_traded\"]).values.flatten()\n",
    "            sequences.append(seq)\n",
    "            labels.append(label)\n",
    "            player_info.append((player_name, group.iloc[i][\"SEASON_START_YEAR\"])) \n",
    "            # need to retain info to know what and whose season we're predicting later on\n",
    "    \n",
    "    return sequences, labels, player_info\n",
    "    # the output needs to be flattened to go back to 1d label structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a150a84c-e1d7-40f0-afc7-01d7d8deebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences, train_labels, train_player_info = create_sequences(train_data)\n",
    "val_sequences, val_labels, val_player_info = create_sequences(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53364812-681a-4ca5-8e4d-8a9ec9ccc29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, dtype=\"float32\", padding=\"pre\", value = -999.0)\n",
    "val_sequences = tf.keras.preprocessing.sequence.pad_sequences(val_sequences, dtype=\"float32\", padding=\"pre\", value = -999.0)\n",
    "\n",
    "# i'm padding the sequences since they variable length sequences can cause problems in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9975e18-118d-40f9-969c-b5b8fb10d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels, dtype=\"float32\")\n",
    "val_labels = np.array(val_labels, dtype=\"float32\")\n",
    "\n",
    "# making sure the labels have the correct dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "809b1e9f-b3e5-444d-9a03-ccf0ed339ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to tf datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_sequences, train_labels))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_sequences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a81c3576-68f6-45c7-95a5-20d007746229",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = train_dataset.shuffle(len(train_sequences)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8265ae63-5374-4190-953d-54dbfe3fa2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_22\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_22\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ masking_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)                 │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ masking_22 (\u001b[38;5;33mMasking\u001b[0m)                 │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_45 (\u001b[38;5;33mLSTM\u001b[0m)                       │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Masking(mask_value= -999.0), # masking the padded parts of the sequence\n",
    "    tf.keras.layers.LSTM(128, return_sequences=False, dropout=0.1, recurrent_dropout=0.05, use_bias=False),  \n",
    "    tf.keras.layers.Dense(train_labels.shape[1], use_bias=False) # no bias to force the model to not learn averages but use past values for predictions\n",
    "]) # i will optimize the model architecture in further iterations. so far, it seems like larger and deeper networks lead to overfitting.\n",
    "\n",
    "# since the data by its nature is very noisy we need to be vary of overfitting to noise! \n",
    "\n",
    "model.compile(optimizer=\"Adam\", loss=\"MSE\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8ccbc23a-4ea7-4501-b227-a2acf025b35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "# early stopping so we stop training when the model stops overfitting, and only save the best model based on out of sample estimates.\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.8, patience=1, min_lr=1e-6)\n",
    "# reduce_lr helps the model stop diverging if its learning rate becomes too large as it gets closer to the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4c5cb286-7ad2-47a2-9aad-93654cfd8929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.2797 - val_loss: 0.2909 - learning_rate: 2.2518e-05\n",
      "Epoch 2/1000\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.2814 - val_loss: 0.2906 - learning_rate: 2.2518e-05\n",
      "Epoch 3/1000\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.2878 - val_loss: 0.2907 - learning_rate: 2.2518e-05\n",
      "Epoch 4/1000\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.2838 - val_loss: 0.2906 - learning_rate: 1.8014e-05\n",
      "Epoch 5/1000\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.2868 - val_loss: 0.2906 - learning_rate: 1.4412e-05\n",
      "Epoch 6/1000\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.2808 - val_loss: 0.2906 - learning_rate: 1.1529e-05\n",
      "Epoch 7/1000\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.2835 - val_loss: 0.2906 - learning_rate: 9.2234e-06\n",
      "Epoch 8/1000\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.2853 - val_loss: 0.2906 - learning_rate: 7.3787e-06\n",
      "Epoch 9/1000\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.2813 - val_loss: 0.2906 - learning_rate: 5.9030e-06\n",
      "Epoch 10/1000\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.2787 - val_loss: 0.2906 - learning_rate: 4.7224e-06\n",
      "Epoch 11/1000\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.2851 - val_loss: 0.2906 - learning_rate: 3.7779e-06\n",
      "Epoch 12/1000\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.2825 - val_loss: 0.2906 - learning_rate: 3.0223e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=1000, batch_size=32, \n",
    "                    validation_data=val_dataset, callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16ae026-e396-4da0-b829-8676c8ee77dc",
   "metadata": {},
   "source": [
    "The MSE loss by itself doesn't mean much. Let's see some actual predictions to see how close we're getting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d8516ce2-bccf-49f6-a4cd-69b8f9d3190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_columns = data.drop(columns=[\"PLAYER_NAME\", \"SEASON_START_YEAR\", \"PLAYER_AGE\", \"is_traded\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "10f7da55-5678-4b02-9cb8-c965c8d0b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_normalize(normalized_preds, means, stds, columns):\n",
    "    \"\"\"\n",
    "    Retransform normalized predictions to the original scale.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(normalized_preds.shape) == 1:\n",
    "        original_preds = np.empty_like(normalized_preds)\n",
    "        for i, col in enumerate(columns):\n",
    "            original_preds[i] = normalized_preds[i] * stds[col] + means[col]\n",
    "    else:\n",
    "        original_preds = np.empty_like(normalized_preds)\n",
    "        for i, col in enumerate(columns):\n",
    "            original_preds[:, i] = normalized_preds[:, i] * stds[col] + means[col]\n",
    "    \n",
    "    return original_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742bea0b-75af-4fdf-8dd9-4cf0b99d6799",
   "metadata": {},
   "source": [
    "Let's compare the prediction of a random season from a random player with its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6735855a-c582-4371-a3c9-6ed9c124515f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions vs Actual Values:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Player: Kenny Smith, Year: 1993\n",
      "Stats:\n",
      "  GP: Actual = 82.0, Prediction = 70.9\n",
      "  MIN_PER_GAME: Actual = 29.5, Prediction = 30.8\n",
      "  FGM_PER_GAME: Actual = 4.7, Prediction = 5.2\n",
      "  FGA_PER_GAME: Actual = 9.1, Prediction = 11.2\n",
      "  FG3M_PER_GAME: Actual = 1.2, Prediction = 0.6\n",
      "  FG3A_PER_GAME: Actual = 2.7, Prediction = 1.8\n",
      "  FTM_PER_GAME: Actual = 2.4, Prediction = 2.6\n",
      "  FTA_PER_GAME: Actual = 2.7, Prediction = 3.2\n",
      "  OREB_PER_GAME: Actual = 0.3, Prediction = 0.4\n",
      "  DREB_PER_GAME: Actual = 1.6, Prediction = 1.7\n",
      "  REB_PER_GAME: Actual = 1.9, Prediction = 2.1\n",
      "  AST_PER_GAME: Actual = 5.4, Prediction = 6.4\n",
      "  STL_PER_GAME: Actual = 1.0, Prediction = 1.1\n",
      "  BLK_PER_GAME: Actual = 0.1, Prediction = 0.1\n",
      "  TOV_PER_GAME: Actual = 2.0, Prediction = 2.4\n",
      "  PF_PER_GAME: Actual = 1.3, Prediction = 1.5\n",
      "  PTS_PER_GAME: Actual = 13.0, Prediction = 13.2\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPredictions vs Actual Values:\")\n",
    "\n",
    "num_predictions = 1\n",
    "random_indices = random.sample(range(len(val_sequences)), num_predictions)\n",
    "\n",
    "for idx in random_indices:\n",
    "    seq = val_sequences[idx:idx+1]  # select the sequence\n",
    "    actual = val_labels[idx]         # select the actual label\n",
    "    prediction = model.predict(seq)  # make prediction\n",
    "    # retransform the normalized prediction back to the original scale\n",
    "    original_prediction = inverse_normalize(prediction, means, stds, stats_columns)\n",
    "    original_actual = inverse_normalize(actual, means, stds, stats_columns)\n",
    "    \n",
    "    player_name, season_year = val_player_info[idx]  # get player info\n",
    "    print(f\"Player: {player_name}, Year: {season_year * stds[\"SEASON_START_YEAR\"] + means[\"SEASON_START_YEAR\"]:.0f}\")\n",
    "    print(\"Stats:\")\n",
    "    for stat, actual_val, pred_val in zip(stats_columns, original_actual, original_prediction[0]):\n",
    "        print(f\"  {stat}: Actual = {actual_val:.1f}, Prediction = {pred_val:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef7f91b-d694-4cb2-b9bf-e6f79a3275e3",
   "metadata": {},
   "source": [
    "For someone a bit more familier, let's predict LeBron James's current and next seasons. \n",
    "\n",
    "(Since the current season is not finished yet and LeBron has only played a fraction of the games, the model will likely assume he was injured this season and lower his numbers aggressively.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bed2a72a-4a79-4cf5-a4c1-905d56cff7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step\n",
      "LeBron's Predicted Stats for the 2024-2025 Season:\n",
      "  GP: 57.6\n",
      "  MIN_PER_GAME: 33.3\n",
      "  FGM_PER_GAME: 8.8\n",
      "  FGA_PER_GAME: 17.6\n",
      "  FG3M_PER_GAME: 2.1\n",
      "  FG3A_PER_GAME: 5.7\n",
      "  FTM_PER_GAME: 3.8\n",
      "  FTA_PER_GAME: 4.9\n",
      "  OREB_PER_GAME: 0.9\n",
      "  DREB_PER_GAME: 6.5\n",
      "  REB_PER_GAME: 7.4\n",
      "  AST_PER_GAME: 7.5\n",
      "  STL_PER_GAME: 1.1\n",
      "  BLK_PER_GAME: 0.7\n",
      "  TOV_PER_GAME: 3.1\n",
      "  PF_PER_GAME: 1.3\n",
      "  PTS_PER_GAME: 23.4\n"
     ]
    }
   ],
   "source": [
    "lebron_data = data_normalized[data_normalized[\"PLAYER_NAME\"] == \"LeBron James\"].sort_values(by=\"SEASON_START_YEAR\").reset_index(drop=True)\n",
    "lebron_sequence = lebron_data.drop(columns=[\"PLAYER_NAME\", \"SEASON_START_YEAR\"]).values\n",
    "lebron_sequence_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                        [lebron_sequence], dtype=\"float32\", padding=\"pre\", value=-999.0, maxlen=train_sequences.shape[1])\n",
    "\n",
    "prediction = model.predict(lebron_sequence_padded)\n",
    "\n",
    "lebron_prediction_original = inverse_normalize(prediction, means, stds, stats_columns)\n",
    "\n",
    "print(f\"LeBron's Predicted Stats for the 2024-2025 Season:\")\n",
    "for stat, pred_val in zip(stats_columns, lebron_prediction_original[0]):\n",
    "    print(f\"  {stat}: {pred_val:.1f}\")"
   ]
  },
  {
   "attachments": {
    "4ab6df4c-4b00-4eb0-8cb5-0a2f4c658b81.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "9ab1f7ab-9871-46b0-bfe5-c294eb7f9c2d",
   "metadata": {},
   "source": [
    "For reference, here are the current values (as of March 11th):\n",
    "![image.png](attachment:4ab6df4c-4b00-4eb0-8cb5-0a2f4c658b81.png)\n",
    "\n",
    "Lebron outperforming expectations as usual!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8a0dcd9d-288d-4a4f-bda2-3ad97bc2ece4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "LeBron's Predicted Stats for the 2025-2026 Season:\n",
      "  GP: 55.5\n",
      "  MIN_PER_GAME: 33.2\n",
      "  FGM_PER_GAME: 8.4\n",
      "  FGA_PER_GAME: 16.9\n",
      "  FG3M_PER_GAME: 2.1\n",
      "  FG3A_PER_GAME: 5.8\n",
      "  FTM_PER_GAME: 3.4\n",
      "  FTA_PER_GAME: 4.2\n",
      "  OREB_PER_GAME: 0.9\n",
      "  DREB_PER_GAME: 6.6\n",
      "  REB_PER_GAME: 7.4\n",
      "  AST_PER_GAME: 7.3\n",
      "  STL_PER_GAME: 1.1\n",
      "  BLK_PER_GAME: 0.7\n",
      "  TOV_PER_GAME: 3.1\n",
      "  PF_PER_GAME: 1.4\n",
      "  PTS_PER_GAME: 22.1\n"
     ]
    }
   ],
   "source": [
    "lebron_data = data_full_normalized[data_full_normalized[\"PLAYER_NAME\"] == \"LeBron James\"].sort_values(by=\"SEASON_START_YEAR\").reset_index(drop=True)\n",
    "lebron_sequence = lebron_data.drop(columns=[\"PLAYER_NAME\", \"SEASON_START_YEAR\"]).values\n",
    "lebron_sequence_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                        [lebron_sequence], dtype=\"float32\", padding=\"pre\", value=-999.0, maxlen=train_sequences.shape[1])\n",
    "\n",
    "prediction = model.predict(lebron_sequence_padded)\n",
    "\n",
    "lebron_prediction_original = inverse_normalize(prediction, means, stds, stats_columns)\n",
    "\n",
    "print(f\"LeBron's Predicted Stats for the 2025-2026 Season:\")\n",
    "for stat, pred_val in zip(stats_columns, lebron_prediction_original[0]):\n",
    "    print(f\"  {stat}: {pred_val:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1157c3a-1daf-4762-8e2b-f5d347b92fb3",
   "metadata": {},
   "source": [
    "It predicts Lebron will be having a 22.1/7.4/7.3 season at 41 years old! We'll see come next year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a12392-684e-49a8-b342-05c05af56229",
   "metadata": {},
   "source": [
    "To finalize, we can predict the current season of all current NBA players, and save the output as a file to use in other projects! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "55bd438c-c8b4-4791-8646-0927cfd03e09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Predictions for the 2025-2026 season have been saved to 'predicted_2025_2026_season.csv'.\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "current_season_players = data_normalized[data_normalized[\"SEASON_START_YEAR\"] == data_normalized[\"SEASON_START_YEAR\"].max()][\"PLAYER_NAME\"].unique()\n",
    "for player in current_season_players:\n",
    "    player_data = data_normalized[data_normalized[\"PLAYER_NAME\"] == player]\n",
    "    player_sequence = player_data.drop(columns=[\"PLAYER_NAME\", \"SEASON_START_YEAR\"]).values\n",
    "    player_sequence_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        [player_sequence], dtype=\"float32\", maxlen=train_sequences.shape[1], padding=\"pre\",value=-999.0\n",
    "    )\n",
    "\n",
    "    prediction = model.predict(player_sequence_padded)\n",
    "    original_prediction = inverse_normalize(prediction, means, stds, stats_columns)\n",
    "    \n",
    "    prediction_dict = dict(zip(stats_columns, original_prediction[0]))\n",
    "    prediction_dict[\"PLAYER_NAME\"] = player\n",
    "    prediction_dict[\"SEASON_START_YEAR\"] = 2025\n",
    "    predictions.append(prediction_dict)\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df.to_csv('predicted_2025_2026_season.csv', index=False)\n",
    "\n",
    "print(\"Predictions for the 2025-2026 season have been saved to 'predicted_2025_2026_season.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f72eda4-9296-4850-8b5c-5a993b49d214",
   "metadata": {},
   "source": [
    "Let's see who are expected to be leading the league in the 3 major stats according to the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e86d42bc-4336-428b-9e50-eea859df5a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Predicted Points Leaders for 2024-2025 Season:\n",
      "\n",
      "            PLAYER_NAME PTS_PER_GAME\n",
      "            Luka Dončić         31.8\n",
      "            Joel Embiid         30.4\n",
      "  Giannis Antetokounmpo         29.4\n",
      "Shai Gilgeous-Alexander         29.0\n",
      "           Jayson Tatum         27.3\n",
      "       Donovan Mitchell         27.0\n",
      "        Anthony Edwards         26.8\n",
      "           Devin Booker         26.1\n",
      "           De'Aaron Fox         25.2\n",
      "             Trae Young         25.1\n"
     ]
    }
   ],
   "source": [
    "top_10_pts_per_game = predictions_df[['PLAYER_NAME', 'PTS_PER_GAME']].sort_values(by='PTS_PER_GAME', ascending=False).head(10)\n",
    "print(\"Top 10 Predicted Points Leaders for 2024-2025 Season:\\n\")\n",
    "print(top_10_pts_per_game.to_string(index=False, formatters={\"PTS_PER_GAME\": \"{:.1f}\".format}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "329481dc-7670-4d65-a76e-146b1119ad9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Predicted Rebounds Leaders for 2024-2025 Season:\n",
      "\n",
      "          PLAYER_NAME REB_PER_GAME\n",
      "     Domantas Sabonis         12.3\n",
      "         Nikola Jokić         11.9\n",
      "        Anthony Davis         11.4\n",
      "          Rudy Gobert         11.3\n",
      "          Jalen Duren         11.2\n",
      "Giannis Antetokounmpo         11.1\n",
      "    Victor Wembanyama         11.0\n",
      "          Joel Embiid         10.5\n",
      "        Jarrett Allen         10.2\n",
      "        Deandre Ayton         10.2\n"
     ]
    }
   ],
   "source": [
    "top_10_reb_per_game = predictions_df[['PLAYER_NAME', 'REB_PER_GAME']].sort_values(by='REB_PER_GAME', ascending=False).head(10)\n",
    "print(\"Top 10 Predicted Rebounds Leaders for 2024-2025 Season:\\n\")\n",
    "print(top_10_reb_per_game.to_string(index=False, formatters={\"REB_PER_GAME\": \"{:.1f}\".format}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "26529a1a-ab9a-4160-8723-f9b83ebdb434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Predicted Assists Leaders for 2024-2025 Season:\n",
      "\n",
      "      PLAYER_NAME AST_PER_GAME\n",
      "Tyrese Haliburton          9.4\n",
      "      Luka Dončić          9.4\n",
      "       Trae Young          9.0\n",
      "     Nikola Jokić          8.4\n",
      "      LaMelo Ball          7.7\n",
      "     James Harden          7.5\n",
      "     LeBron James          7.5\n",
      "        Ja Morant          7.2\n",
      "   Damian Lillard          6.8\n",
      " Domantas Sabonis          6.8\n"
     ]
    }
   ],
   "source": [
    "top_10_ast_per_game = predictions_df[['PLAYER_NAME', 'AST_PER_GAME']].sort_values(by='AST_PER_GAME', ascending=False).head(10)\n",
    "print(\"Top 10 Predicted Assists Leaders for 2024-2025 Season:\\n\")\n",
    "print(top_10_ast_per_game.to_string(index=False, formatters={\"AST_PER_GAME\": \"{:.1f}\".format}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d7425d-ad49-4ec6-b812-ef2064e0747c",
   "metadata": {},
   "source": [
    "It came pretty close in most cases. Sudden player progressions like Cade Cunningham or injury situations like Joel Embiid this season are hard to predict, but it seemed to do a good job in most regular cases! \n",
    "\n",
    "Let's see what the average error was for each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "9394725e-5ef6-4a69-bddd-9939c35a8d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Absolute Errors:\n",
      "\n",
      "GP: ±16.1\n",
      "MIN_PER_GAME: ±4.1\n",
      "FGM_PER_GAME: ±0.8\n",
      "FGA_PER_GAME: ±1.6\n",
      "FG3M_PER_GAME: ±0.3\n",
      "FG3A_PER_GAME: ±0.8\n",
      "FTM_PER_GAME: ±0.4\n",
      "FTA_PER_GAME: ±0.5\n",
      "OREB_PER_GAME: ±0.3\n",
      "DREB_PER_GAME: ±0.6\n",
      "REB_PER_GAME: ±0.8\n",
      "AST_PER_GAME: ±0.6\n",
      "STL_PER_GAME: ±0.2\n",
      "BLK_PER_GAME: ±0.1\n",
      "TOV_PER_GAME: ±0.3\n",
      "PF_PER_GAME: ±0.4\n",
      "PTS_PER_GAME: ±2.2\n"
     ]
    }
   ],
   "source": [
    "merged_df = predictions_df.merge(data_full, on=[\"PLAYER_NAME\", \"SEASON_START_YEAR\"], suffixes=(\"_pred\", \"_actual\"))\n",
    "\n",
    "error_dict = {}\n",
    "for stat in stats_columns:\n",
    "    error_dict[stat] = (merged_df[f\"{stat}_pred\"] - merged_df[f\"{stat}_actual\"]).abs().mean()\n",
    "\n",
    "print(\"\\nAverage Absolute Errors:\\n\")\n",
    "for stat, error in error_dict.items():\n",
    "    print(f\"{stat}: ±{error:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ecc940-7d3a-4a5a-8ece-18239505ce0d",
   "metadata": {},
   "source": [
    "Pretty good! Most of these are basically rounding errors. This data was excluded from the training and validation sets as well, so this proves the model is quite robust.\n",
    "\n",
    "Note that GP is pretty high only because the 2024-25 season isn't over yet. As more games are played, that value will shrink and the other errors might actually decrease as well :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
